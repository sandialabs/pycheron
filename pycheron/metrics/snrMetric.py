#####################################################################################
# Copyright 2019 National Technology & Engineering Solutions of Sandia, LLC (NTESS).
# Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains
# certain rights in this software.
#####################################################################################
# NOTICE:
# For five (5) years from 10/21/2019 the United States Government is granted for
# itself and others acting on its behalf a paid-up, nonexclusive, irrevocable worldwide
# license in this data to reproduce, prepare derivative works, and perform publicly and
# display publicly, by or on behalf of the Government. There is provision for the
# possible extension of the term of this license. Subsequent to that period or any
# extension granted, the United States Government is granted for itself and others
# acting on its behalf a paid-up, nonexclusive, irrevocable worldwide license in this
# data to reproduce, prepare derivative works, distribute copies to the public,
# perform publicly and display publicly, and to permit others to do so. The specific
# term of the license can be identified by inquiry made to National Technology and
# Engineering Solutions of Sandia, LLC or DOE. NEITHER THE UNITED STATES GOVERNMENT,
# NOR THE UNITED STATES DEPARTMENT OF ENERGY, NOR NATIONAL TECHNOLOGY AND ENGINEERING
# SOLUTIONS OF SANDIA, LLC, NOR ANY OF THEIR EMPLOYEES, MAKES ANY WARRANTY, EXPRESS OR
# IMPLIED, OR ASSUMES ANY LEGAL RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR
# USEFULNESS OF ANY INFORMATION, APPARATUS, PRODUCT, OR PROCESS DISCLOSED, OR REPRESENTS
# THAT ITS USE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS. Any licensee of this software
# has the obligation and responsibility to abide by the applicable export control laws,
# regulations, and general prohibitions relating to the export of technical data.
# Failure to obtain an export control license or other authority from the Government
# may result in criminal liability under U.S. laws.
# (End of Notice)
####################################################################################

__all__ = ["snrMetric"]

import numpy as np
import obspy.core.event as event
from pycheron.psd.noise.deadChannel import isDC
from pycheron.psd.noise.deadChannel import DDT
from pycheron.sigpro.STALTA import STALTA
from pycheron.sigpro.triggerOnset import triggerOnset
from pycheron.util.logger import Logger


def snrMetric(
    st,
    algorithm="splitWindow",
    windowSecs=60,
    snrThreshold=2,
    generateMasks=False,
    masksByTime=True,
    logger=None,
    database=None,
):
    """
    Calculates Signal to Noise Ratio from an obspy stream object.

    :param st: obspy stream object
    :type st: obspy.core.stream.Stream
    :param algorithm: a named algorithm to use for calculating SNR. Options include 'splitWindow', 'staltaTrigger', and
           'pick'. See Algorithm_Options_ .
    :type algorithm: str
    :param windowSecs: Width (secs) of the full window used in SNR calculation.
    :type windowSecs: int
    :param snrThreshold: SNR threshold at which if above, value would be masked.
    :type snrThreshold: int
    :param generateMasks: If thrue masks will be outputed.
    :type generateMasks: bool
    :param masksByTime: Boolean to determine whether masks are generated by time. If True, masks will be generated with
           a start/end time, if false, they will be generated as boolean array.
    :type masksByTime: bool
    :param logger: logger object
    :type logger: pycheron.util.logger.Logger
    :param database: database object
    :type database: pycheron.db.sqllite_db.Database

    :return: dictionary containing the following keys and types:

                * algorithm (`str`)
                * snclq (`str`)
                * start_time (`str`)
                * end_time (`str`)
                * snr (`float`)
                * windowSecs (`int`)
                * metric_name (`str`)
                * masks (`list` or `numpy.ndarray`)

    :rtype: dict

    Calculates Signal to Noise Ratio from single Trace. Calculates a signal/noise ratio comparing the standard deviation
    by dividing the incoming stream into two equal parts.  It is assumed that the stream starttime and endtime
    are equally spaced about the onset of a seismic event (for split-window option).

    Seismic signals in the Stream should ideally be without gaps, i.e. contained within a single Trace. Currently
    have a workaround that checks if gaps exist in the data (e.g., is there more than one trace with the same snclq,
    if so merge traces together and append gap area (essentially ignoring it) This will cause problems in the rare case
    where the event started in the gap area. This should be a rare occurrence so should be ok. Ideally you wouldn't use
    these types of traces.

    .. _Algorithm_Options:

    **Algorithm Options**

    * "splitWindow":
         * This algorithm uses the midpoint of the seismic signal as the border between noise to the left
           of the midpoint and signal to the right. The value for signal-to-noise is just the rmsVariance
           calculated for windowSecs/2 seconds of data to the right of the midpoint divided by the
           rmsVariance for windowSecs/2 seconds of data to the left of the midpoint.

    * "staltaTrigger":
         * This algorithm uses classic LR to identify event and window noise and signal windows. -- Needs
           more testing. Currently agrees with R codes but varies considerably from splitWindow estimate
           for same time window. This may be due to the fact though that the event is not centered within
           the trace segment, so the staltaTrigger finds the noise/signal windows more effectively than
           the split window

    * "pick":
         * This algorithm uses first arrival pick information within a sac trace header (tr.stats.sac.a)
           to identify event noise and signal windows. This is an addition to R codes, may consider
           adapting header to be user defined so that it can work with different kinds of traces.

    **Example**

    .. code-block:: python

        #Initialize client object
        client = Client("IRIS")

        #Get an hours worth of data from 02/27/2010 06:16:15:07:16:15
        t = UTCDateTime("2010-02-27T06:16:15.000")
        st = client.get_waveforms("IU","ANMO", "00","BHZ",t,t+60*60)

        #Get snr ratio with splitWindow algorithm
        snrMetric(st,algorithm='splitWindow',windowSecs = 60)
        >>> [{'End Time': 2010-02-27T07:16:14.969538Z, 'SNR': 9.82051194437024, 'Start Time': 2010-02-27T06:16:15.019538Z, 'algorithm': 'splitWindow', 'metric_name': 'snrMetric', 'snclq': u'IU.ANMO.00.BHZ.M', 'snr_masks': None, 'windowSecs': 60}]

    """

    if logger == None:
        logger = Logger(None)

    # Initialize output list
    d = []
    snrMasks = None

    # Check if gaps in data, if so merge traces together and append gap area essentially ignoring it. This will cause
    # problems in the rare case where the event started in the gap area. This should be a rare occurrence so should be
    # ok.
    if len(st.get_gaps()) > 0:
        # Merge stream objects with same IDs, if gaps present, fill with '999999', then remove '999999' values from
        # trace. Make copy of stream object to retain original stream, otherwise will be permanently changed
        stC = st.copy()
        stM = stC.merge(fill_value=999999)
        for trace in stM:
            tr = trace
            tr.data = tr.data[tr.data != 999999]
    else:
        # Only making copy for consistency with gap case
        stM = st.copy()

    # Grab out trace objects and loop through
    for trace in stM:
        tr = trace
        # if tr is not from mseed
        try:
            snclq = tr.get_id() + "." + tr.stats.mseed.dataquality
        except AttributeError:
            snclq = tr.get_id()
        starttime = tr.stats.starttime
        endtime = tr.stats.endtime
        # ------Error Testing------------------------------------------------------
        # Check if there is enough data
        if (tr.stats.endtime - tr.stats.starttime) < 60:
            snr = "Not calculated because data does not fill the window"
            metrics = {
                "algorithm": None,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "comment": "endtime-starttime < 60",
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }
            d.append(metrics)

        # Check if the data are flat-lined, e.g., DC signal
        # First copy data so don't permanently alter original trace
        trC = tr.copy()
        if (isDC(trC)) is True:
            snr = 0
            if generateMasks == True:
                if snr <= snrThreshold:
                    if masksByTime:
                        snrMasks = [
                            {
                                "Starttime": starttime.isoformat(),
                                "Endtime": endtime.isoformat(),
                            }
                        ]
                    else:
                        snrMasks = np.ones(len(tr.data))
            metrics = {
                "algorithm": None,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "comment": "trace is flat, dead channel",
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }
            d.append(metrics)

        # ---------Function--------------------------------------------------------
        # Split Window
        # In this case, the window is assumed to be centered about an event, where event is perhaps determined with some
        # other software or webservice, or pulled from a bulletin. The time increment is just the midpoint of the trace
        # centered about the event (e.g., triggerOnset is t_int)
        if algorithm == "splitWindow":
            # Get time increment centered about event
            t_int = starttime + ((endtime - starttime) / 2)
            # Grab noise and signal slices based on t_int
            trN = tr.slice((t_int - (windowSecs / 2)), t_int)
            trS = tr.slice(t_int, (t_int + (windowSecs / 2)))
            # Take rms variance to get signal-to-noise ratio (snr) -- this is really std deviation but R codes call it
            # RMS variance
            rmsVarianceS = np.sqrt(np.var(trS.data))
            rmsVarianceN = np.sqrt(np.var(trN.data))
            snr = rmsVarianceS / rmsVarianceN
            # create masks
            if generateMasks == True:
                if masksByTime:
                    snrMasks = [
                        {
                            "start_time": starttime.isoformat(),
                            "end_time": endtime.isoformat(),
                        }
                    ]
                else:
                    snrMasks = np.ones(len(tr.data))
            # Create metrics list to append to from each stream object
            metrics = {
                "algorithm": algorithm,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }
            d.append(metrics)

        # ---------Function--------------------------------------------------------
        # staltaTrigger
        # This algorithm uses classic LR to identify event and window noise and signal windows.
        elif algorithm == "staltaTrigger":
            # Demean and detrend data first
            # First copy the data so don't permanently alter trace
            trC1 = tr.copy()
            trC1 = DDT(trC1, True, True, 0)

            # Find the P-wave onset with "classic_LR"
            staSecs = 3
            ltaSecs = 30

            # Make sure that there are at least two points in the STA window
            if (int(staSecs * trC1.stats.sampling_rate)) < 1:
                staSecs = 2 / trC1.stats.sampling_rate
                ltaSecs = staSecs * 5

            picker = STALTA(trC1, staSecs, ltaSecs, logger)
            to = triggerOnset(trC1, picker)

            # # Adjust value given that we removed nans from initial calculation, otherwise will be slightly off
            # to_int = int(np.argwhere(~np.isnan(picker))[0])
            # to += to_int / trC1.stats.sampling_rate
            trN = trC1.slice(to - windowSecs / 2, to)
            trS = trC1.slice(to, to + windowSecs / 2)
            rmsVarianceS = np.sqrt(np.var(trS.data))
            rmsVarianceN = np.sqrt(np.var(trN.data))
            snr = rmsVarianceS / rmsVarianceN
            # create masks
            if generateMasks == True:
                if masksByTime:
                    snrMasks = [
                        {
                            "start_time": starttime.isoformat(),
                            "end_time": endtime.isoformat(),
                        }
                    ]
                else:
                    snrMasks = np.ones(len(tr.data))
            # Create metrics list to append to from each stream object
            metrics = {
                "algorithm": algorithm,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }

            d.append(metrics)
            # ---------Function--------------------------------------------------------
            # Pick
            # In this case, the noise and signal windows are picked
        elif algorithm == "pick":
            # Get time increment centered about event using pick in sac head, assumes pick is in
            # tr.stats.sac.a variable
            if isinstance(tr.stats.first_arrival, event.origin.Pick):
                t_int = tr.stats.first_arrival.time
            else:
                t_int = starttime + 60 + tr.stats.first_arrival.time

            # Grab noise and signal slices based on t_int
            trN = tr.slice((t_int - (windowSecs / 2)), t_int)
            trS = tr.slice(t_int, (t_int + (windowSecs / 2)))

            # Take rms variance to get signal-to-noise ratio (snr)
            rmsVarianceS = np.sqrt(np.var(trS.data))
            rmsVarianceN = np.sqrt(np.var(trN.data))
            snr = rmsVarianceS / rmsVarianceN
            # create masks
            if generateMasks == True:
                if masksByTime:
                    snrMasks = [
                        {
                            "start_time": starttime.isoformat(),
                            "end_time": endtime.isoformat(),
                        }
                    ]
                else:
                    snrMasks = np.ones(len(tr.data))
            # Create metrics list to append to from each stream object
            metrics = {
                "algorithm": algorithm,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "snr": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }

            d.append(metrics)

        else:
            logger.error(
                "snrMetric Error: Algorithm: {a} not found, please choose from: pick, splitWindow, staltaTrigger ".format(
                    a=algorithm
                )
            )

    if database is not None:
        database.insert_metric(d)
    return d
