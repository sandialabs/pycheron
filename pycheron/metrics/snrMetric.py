#####################################################################################
# Copyright 2019 National Technology & Engineering Solutions of Sandia, LLC (NTESS).
# Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains
# certain rights in this software.
#####################################################################################
# NOTICE:
# For five (5) years from 10/21/2019 the United States Government is granted for
# itself and others acting on its behalf a paid-up, nonexclusive, irrevocable worldwide
# license in this data to reproduce, prepare derivative works, and perform publicly and
# display publicly, by or on behalf of the Government. There is provision for the
# possible extension of the term of this license. Subsequent to that period or any
# extension granted, the United States Government is granted for itself and others
# acting on its behalf a paid-up, nonexclusive, irrevocable worldwide license in this
# data to reproduce, prepare derivative works, distribute copies to the public,
# perform publicly and display publicly, and to permit others to do so. The specific
# term of the license can be identified by inquiry made to National Technology and
# Engineering Solutions of Sandia, LLC or DOE. NEITHER THE UNITED STATES GOVERNMENT,
# NOR THE UNITED STATES DEPARTMENT OF ENERGY, NOR NATIONAL TECHNOLOGY AND ENGINEERING
# SOLUTIONS OF SANDIA, LLC, NOR ANY OF THEIR EMPLOYEES, MAKES ANY WARRANTY, EXPRESS OR
# IMPLIED, OR ASSUMES ANY LEGAL RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR
# USEFULNESS OF ANY INFORMATION, APPARATUS, PRODUCT, OR PROCESS DISCLOSED, OR REPRESENTS
# THAT ITS USE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS. Any licensee of this software
# has the obligation and responsibility to abide by the applicable export control laws,
# regulations, and general prohibitions relating to the export of technical data.
# Failure to obtain an export control license or other authority from the Government
# may result in criminal liability under U.S. laws.
# (End of Notice)
####################################################################################

__all__ = ["snrMetric"]

import numpy as np
import obspy.core.event as event
from pycheron.psd.noise.deadChannel import isDC
from pycheron.psd.noise.deadChannel import DDT
from pycheron.sigpro.STALTA import STALTA
from pycheron.sigpro.triggerOnset import triggerOnset
from pycheron.util.logger import Logger
from pycheron.db.sqllite_db import Database


def snrMetric(
    st,
    algorithm="splitWindow",
    windowSecs=60,
    snrThreshold=2,
    generateMasks=False,
    masksByTime=True,
    logger=None,
    database_config=None,
):
    """
    Calculates Signal to Noise Ratio of an ObsPy Stream object using 'splitWindow', 'staltaTrigge' or 'pick options

    :param st: ObsPy Stream object
    :type st: obspy.core.stream.Stream
    :param algorithm: a named algorithm to use for calculating SNR. Options include 'splitWindow', 'staltaTrigger', and
           'pick'. See Algorithm_Options_ .
    :type algorithm: str
    :param windowSecs: Width (secs) of the full window used in SNR calculation.
    :type windowSecs: int
    :param snrThreshold: SNR threshold at which if above, value would be masked.
    :type snrThreshold: int
    :param generateMasks: If thrue masks will be outputed.
    :type generateMasks: bool
    :param masksByTime: Boolean to determine whether masks are generated by time. If True, masks will be generated with
           a start/end time, if false, they will be generated as boolean array.
    :type masksByTime: bool
    :param logger: logger object
    :type logger: pycheron.util.logger.Logger
    :param database_config: dictionary containing the necessary parameters to create
                            a pycheron Database object. 
                            These include "db_name", "session_name", "overwrite", "manual", "wfdb_conn"
    :type database_config: dict

    :return: dictionary containing the following keys and types:

                * algorithm (`str`)
                * snclq (`str`)
                * start_time (`str`)
                * end_time (`str`)
                * snr (`float`)
                * windowSecs (`int`)
                * metric_name (`str`)
                * masks (`list` or `numpy.ndarray`)

    :rtype: dict

    Calculates Signal to Noise Ratio from single Trace. Calculates a signal/noise ratio by comparing the RMS Variance
    by dividing the incoming stream into two equal parts
    (https://cran.r-project.org/web/packages/IRISMustangMetrics/IRISMustangMetrics.pdf). The split-window algorithm
    option assumes that the stream starttime and endtime are equally spaced about the onset of a seismic event.

    Seismic signals in the Stream should ideally be without gaps, i.e. contained within a single Trace. Currently
    have a workaround that checks if gaps exist in the data (e.g., is there more than one trace with the same snclq,
    if so merge traces together and append gap area (essentially ignoring it) This will cause problems in the rare case
    where the event started in the gap area. This should be a rare occurrence, so it should be ok. Ideally you wouldn't
    use those types of traces anyway.

    .. _Algorithm_Options:

    **Algorithm Options**

    * "splitWindow":
         * "This algorithm uses the midpoint of the seismic signal as the border between noise to the left
           of the midpoint and signal to the right. The value for signal-to-noise is just the rmsVariance
           calculated for windowSecs/2 seconds of data to the right of the midpoint divided by the
           rmsVariance for windowSecs/2 seconds of data to the left of the midpoint."
           (https://cran.r-project.org/web/packages/IRISMustangMetrics/IRISMustangMetrics.pdf)

    * "staltaTrigger":
         * This algorithm uses classic LR to identify event and window noise and signal windows. -- Needs
           more testing. Currently agrees with R codes but varies considerably from splitWindow estimate
           for same time window. This may be due to the fact though that the event is not centered within
           the trace segment, so the staltaTrigger finds the noise/signal windows more effectively than
           the split window

    * "pick":
         * This algorithm uses first arrival pick information within a sac trace header
           (tr.stats.sac.a) to identify event noise and signal windows. This is an addition to R codes by the Pycheron
           team. Need to consider adapting header to be user defined so that it can work with different kinds of traces.

    * Code originally ported from IRISMustangMetrics R Cran Package
    (Callahan, J., R. Casey, M. Templeton, and G. Sharer (2020, March 20). CRAN-Package IRISMustangMetrics.
    The Comprehensive R Archive Network. Retrieved from
    https://cran.r-project.org/web/packages/IRISMustangMetrics/index.html) and augmented and adapted for use within
    Pycheron

    **Example**

    .. code-block:: python

        #Initialize client object
        client = Client("IRIS")

        #Get an hours worth of data from 02/27/2010 06:16:15:07:16:15
        t = UTCDateTime("2010-02-27T06:16:15.000")
        st = client.get_waveforms("IU","ANMO", "00","BHZ",t,t+60*60)

        #Get snr ratio with splitWindow algorithm
        snrMetric(st,algorithm='splitWindow',windowSecs = 60)
        >>> [{'End Time': 2010-02-27T07:16:14.969538Z, 'SNR': 9.82051194437024,
              'Start Time': 2010-02-27T06:16:15.019538Z, 'algorithm': 'splitWindow', 'metric_name': 'snrMetric',
              'snclq': u'IU.ANMO.00.BHZ.M', 'snr_masks': None, 'windowSecs': 60}]

    """

    # Set up logger
    if logger is None:
        logger = Logger(None)

    # Initialize output list
    d = []
    snrMasks = None

    # Check if gaps in data, if so merge traces together and append gap area essentially ignoring it. This will cause
    # problems in the rare case where the event started in the gap area. This should be a rare occurrence so should be
    # ok as we probably wouldn't want to use those traces anyway.
    if len(st.get_gaps()) > 0:
        # Merge stream objects with same IDs, if gaps present, fill with '999999', then remove '999999' values from
        # trace. Make copy of stream object to retain original stream, otherwise will be permanently changed
        stC = st.copy()
        stM = stC.merge(fill_value=999999)
        for trace in stM:
            tr = trace
            tr.data = tr.data[tr.data != 999999]
    else:
        # Only making copy for consistency with gap case
        stM = st.copy()

    # Grab out trace objects and loop through them
    for trace in stM:
        tr = trace
        # Try getting data quality info, if miniseed file
        try:
            snclq = tr.get_id() + "." + tr.stats.mseed.dataquality
        # Otherwise just grab out it
        except AttributeError:
            snclq = tr.get_id()
        # Get start/end times
        starttime = tr.stats.starttime
        endtime = tr.stats.endtime
        # ------Error Testing------------------------------------------------------
        # Check if there is enough data
        if (tr.stats.endtime - tr.stats.starttime) < windowSecs:
            snr = "Not calculated because data does not fill the window"
            metrics = {
                "algorithm": None,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }
            d.append(metrics)

        # Check if the data are flat-lined, e.g., DC signal
        # First copy data so don't permanently alter original trace
        trC = tr.copy()
        # Check if flat-lined
        if isDC(trC):
            snr = 0
            # If generateMasks True and either generate mask times for entire time period or boolean array
            if generateMasks:
                if snr <= snrThreshold:
                    if masksByTime:
                        snrMasks = [
                            {
                                "Starttime": starttime.isoformat(),
                                "Endtime": endtime.isoformat(),
                            }
                        ]
                    else:
                        snrMasks = np.ones(len(tr.data))
            # Create dictionary object
            metrics = {
                "algorithm": None,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }
            # Append to list
            d.append(metrics)

        # ---------Function--------------------------------------------------------
        # Split Window
        # In this case, the window is assumed to be centered about an event, where event is perhaps determined with some
        # other software or webservice, or pulled from a bulletin. The time increment is just the midpoint of the trace
        # centered about the event (e.g., triggerOnset is t_int)
        if algorithm == "splitWindow":
            # Get time increment centered about event
            t_int = starttime + ((endtime - starttime) / 2)
            # Grab noise and signal slices based on t_int
            trN = tr.slice((t_int - (windowSecs / 2)), t_int)
            trS = tr.slice(t_int, (t_int + (windowSecs / 2)))
            # Take rms variance to get signal-to-noise ratio (snr) -- this is really std deviation but R codes call it
            # RMS variance
            rmsVarianceS = np.sqrt(np.var(trS.data))
            rmsVarianceN = np.sqrt(np.var(trN.data))
            snr = rmsVarianceS / rmsVarianceN
            # create masks
            if generateMasks:
                if masksByTime:
                    snrMasks = [
                        {
                            "start_time": starttime.isoformat(),
                            "end_time": endtime.isoformat(),
                        }
                    ]
                else:
                    snrMasks = np.ones(len(tr.data))
            # Create metrics list to append to from each stream object
            metrics = {
                "algorithm": algorithm,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }
            d.append(metrics)

        # ---------Function--------------------------------------------------------
        # staltaTrigger
        # This algorithm uses classic LR to identify event and window noise and signal windows.
        elif algorithm == "staltaTrigger":
            # First copy the data so don't permanently alter trace
            # Then Demean and detrend data
            trC1 = tr.copy()
            trC1 = DDT(trC1, True, True, 0)

            # Find the P-wave onset with "classic_LR"
            staSecs = 3
            ltaSecs = 30

            # Ensure there are at least two points in the STA window
            if (int(staSecs * trC1.stats.sampling_rate)) < 1:
                staSecs = 2 / trC1.stats.sampling_rate
                ltaSecs = staSecs * 5
            # Calculate stalta
            # Uses vector returned by STALTA "first break picking" method and a user selected threshold
            # to determine the arrival time of a seismic event.
            picker = STALTA(trC1, staSecs, ltaSecs, logger)
            to = triggerOnset(trC1, picker)

            # # Adjust value given that we removed nans from initial calculation, otherwise will be slightly off
            # to_int = int(np.argwhere(~np.isnan(picker))[0])
            # to += to_int / trC1.stats.sampling_rate
            # Grab out noise trace and signal trace, calculate their RMS Variance and then calculate SNR
            trN = trC1.slice(to - windowSecs / 2, to)
            trS = trC1.slice(to, to + windowSecs / 2)
            rmsVarianceS = np.sqrt(np.var(trS.data))
            rmsVarianceN = np.sqrt(np.var(trN.data))
            snr = rmsVarianceS / rmsVarianceN
            # create masks
            if generateMasks:
                # If by time, generate dictionary of times
                if masksByTime:
                    snrMasks = [
                        {
                            "start_time": starttime.isoformat(),
                            "end_time": endtime.isoformat(),
                        }
                    ]
                # Otherwise generate boolean mask array
                else:
                    snrMasks = np.ones(len(tr.data))
            # Create metrics list to append to from each stream object
            metrics = {
                "algorithm": algorithm,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "SNR": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }

            d.append(metrics)
            # ---------Function--------------------------------------------------------
            # Pick
            # In this case, the noise and signal windows are picked
        elif algorithm == "pick":
            # Get time increment centered about event using pick in sac head, assumes pick is in
            # tr.stats.sac.a variable
            if isinstance(tr.stats.first_arrival, event.origin.Pick):
                t_int = tr.stats.first_arrival.time
            else:
                t_int = starttime + 60 + tr.stats.first_arrival.time

            # Grab noise and signal slices based on t_int
            trN = tr.slice((t_int - (windowSecs / 2)), t_int)
            trS = tr.slice(t_int, (t_int + (windowSecs / 2)))

            # Take rms variance to get signal-to-noise ratio (snr)
            rmsVarianceS = np.sqrt(np.var(trS.data))
            rmsVarianceN = np.sqrt(np.var(trN.data))
            snr = rmsVarianceS / rmsVarianceN
            # create masks
            if generateMasks:
                # If by time, generate dictionary of times
                if masksByTime:
                    snrMasks = [
                        {
                            "start_time": starttime.isoformat(),
                            "end_time": endtime.isoformat(),
                        }
                    ]
                # Otherwise generate boolean mask array
                else:
                    snrMasks = np.ones(len(tr.data))
            # Create metrics list to append to from each stream object
            metrics = {
                "algorithm": algorithm,
                "snclq": snclq,
                "start_time": starttime.isoformat(),
                "end_time": endtime.isoformat(),
                "snr": snr,
                "windowSecs": windowSecs,
                "metric_name": "snrMetric",
                "masks": snrMasks,
            }

            d.append(metrics)

        else:
            # Error if user provides unrecognized algorithm
            logger.error(
                "snrMetric Error: Algorithm: {a} not found, please choose from: pick, \
                                     splitWindow, staltaTrigger ".format(
                    a=algorithm
                )
            )

    # If database defined, insert metric information
    if database_config is not None:
        database = Database(**database_config)
        database.insert_metric(d)

    return d
