#####################################################################################
# Copyright 2019 National Technology & Engineering Solutions of Sandia, LLC (NTESS).
# Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains
# certain rights in this software.
#####################################################################################
# NOTICE:
# For five (5) years from 10/21/2019 the United States Government is granted for
# itself and others acting on its behalf a paid-up, nonexclusive, irrevocable worldwide
# license in this data to reproduce, prepare derivative works, and perform publicly and
# display publicly, by or on behalf of the Government. There is provision for the
# possible extension of the term of this license. Subsequent to that period or any
# extension granted, the United States Government is granted for itself and others
# acting on its behalf a paid-up, nonexclusive, irrevocable worldwide license in this
# data to reproduce, prepare derivative works, distribute copies to the public,
# perform publicly and display publicly, and to permit others to do so. The specific
# term of the license can be identified by inquiry made to National Technology and
# Engineering Solutions of Sandia, LLC or DOE. NEITHER THE UNITED STATES GOVERNMENT,
# NOR THE UNITED STATES DEPARTMENT OF ENERGY, NOR NATIONAL TECHNOLOGY AND ENGINEERING
# SOLUTIONS OF SANDIA, LLC, NOR ANY OF THEIR EMPLOYEES, MAKES ANY WARRANTY, EXPRESS OR
# IMPLIED, OR ASSUMES ANY LEGAL RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR
# USEFULNESS OF ANY INFORMATION, APPARATUS, PRODUCT, OR PROCESS DISCLOSED, OR REPRESENTS
# THAT ITS USE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS. Any licensee of this software
# has the obligation and responsibility to abide by the applicable export control laws,
# regulations, and general prohibitions relating to the export of technical data.
# Failure to obtain an export control license or other authority from the Government
# may result in criminal liability under U.S. laws.
# (End of Notice)
####################################################################################

__all__ = ["spikesMetric"]

import numpy as np
from pycheron.psd.noise.findOutliers import findOutliers
import multiprocessing as mp
from pycheron.util.masks import samples2time
from pycheron.util.logger import Logger


def spikesMetric(
    st,
    windowSize=41,
    threshold=10,
    selectivity=None,
    fixedThreshold=True,
    generateMasks=False,
    masksByTime=True,
    processes=4,
    logger=None,
    fortran=True,
    database=None,
):
    """
    Determines number of spikes in a seismic stream.

    :param st: (stream) - obspy stream object
    :type st: obspy.core.stream.Stream
    :param windowSize: size of window to be used (e.g., window size to roll over.
    :type windowSize: int
    :param threshold: initial threshold value for outlier detection.
    :type threshold: float
    :param selectivity: Range from 0-1 used in determining outliers, or None if fixedThreshold = TRUE
    :type selectivity: float
    :param fixedThreshold: (boolean) - if `True`, set the threshold = threshold and ignore selectivity. If `False`, then
                                       the threshold is set to the maximum value of the hampel/hampelFilter function
                                       output multiplied by the selectivity
    :type fixedThreshold: bool
    :param generateMasks: If `True`, a boolean mask array is created for spike values, if `False` mask returns
                                      `None`.
    :type generateMasks: bool
    :param masksByTime: Boolean to determine whether masks are generated by time. If True, masks will be
                                 generated with a start/end time, if false, they will be generated as boolean array.
    :type masksByTime: bool
    :param processes: Number of processes to use for calculation.
    :type processes: int
    :param logger: logger object
    :type logger: pycheron.util.logger.Logger
    :param fortran: Use Fortran libs or not. If libs will not compile or on a Windows Machine, set to `False`
    :type fortran: bool
    :param database: database object
    :type database: pycheron.db.sqllite_db.Database

    :return: list of dictionaries with following keys and types:

        * snclq (`str`)
        * spike_times (`list`)
        * total_spike_count (`int`)
        * non_adjacent_spikes (`int`)
        * start_time (`str`)
        * end_time (`str`)
        * mask (`numpy.ndarray` or `list`)
        * metric_name (`str`)

    :rtype: list

    **Parameter Notes**

    * threshold (`float`)
        * Threshold level is similar to a sigma value for normally distributed data. Hampel filter values
          above 6.0 indicate a data value that is extremely unlikely to be part of a normal distribution
          (~1/500 million) and therefore likely to be an outlier. By choosing a relatively large value for
          threshold min one can make it less likely that we will generate false positives. False positives
          can include high frequency environmental noise.
    * selectivity (`float`)
        * The selectivity is a value between 0 and 1 and is used to generate an appropriate threshold for
          outlier detection based on the statistics of the incoming data. A lower value for selectivity
          will result in more outliers while a value closer to 1.0 will result in fewer.

    **Example**

    .. code-block:: python

        #test data
        data = 'test/test_data/spike_example_1hrseg.mseed'

        #reading in stream
        st = obspy.read(data)

        #setting parameters
        windowSize=41
        threshold=6
        selectivity=None
        fixedThreshold = True

        spikes = spikesMetric(st, windowSize, threshold, selectivity, fixedThreshold)
        print spikes
        >>> [{'total_spike_count': 117, 'non-adjacent_spikes': 51, 'masks': None, 'metric_name': 'spikesMetric', 'spike_times': ['2013-01-03T15:03:38.598133', '2013-01-03T15:03:38.623133', '2013-01-03T15:03:45.273133', '2013-01-03T15:03:45.298133', '2013-01-03T15:03:51.123133', '2013-01-03T15:03:51.148133', '2013-01-03T15:05:38.523133', '2013-01-03T15:05:38.548133', '2013-01-03T15:05:38.573133', '2013-01-03T15:05:38.598133', '2013-01-03T15:07:41.123133', '2013-01-03T15:07:41.148133', '2013-01-03T15:07:41.173133', '2013-01-03T15:07:41.198133', '2013-01-03T15:07:45.223133', '2013-01-03T15:08:09.048133', '2013-01-03T15:08:09.073133', '2013-01-03T15:08:31.373133', '2013-01-03T15:08:31.398133', '2013-01-03T15:08:31.423133', '2013-01-03T15:08:38.323133', '2013-01-03T15:09:00.998133', '2013-01-03T15:09:01.023133', '2013-01-03T15:09:01.048133', '2013-01-03T15:10:50.348133', '2013-01-03T15:11:22.448133', '2013-01-03T15:11:46.698133', '2013-01-03T15:12:54.573133', '2013-01-03T15:12:58.423133', '2013-01-03T15:12:58.448133', '2013-01-03T15:12:58.473133', '2013-01-03T15:12:58.498133', '2013-01-03T15:13:39.798133', '2013-01-03T15:13:39.823133', '2013-01-03T15:15:34.948133', '2013-01-03T15:15:34.973133', '2013-01-03T15:15:34.998133', '2013-01-03T15:15:40.148133', '2013-01-03T15:15:40.173133', '2013-01-03T15:15:56.348133', '2013-01-03T15:17:23.873133', '2013-01-03T15:17:54.773133', '2013-01-03T15:18:13.398133', '2013-01-03T15:18:13.423133', '2013-01-03T15:18:13.448133', '2013-01-03T15:18:13.473133', '2013-01-03T15:18:13.498133', '2013-01-03T15:20:50.623133', '2013-01-03T15:21:11.648133', '2013-01-03T15:21:11.673133', '2013-01-03T15:21:11.698133', '2013-01-03T15:21:11.723133', '2013-01-03T15:22:33.198133', '2013-01-03T15:23:09.323133', '2013-01-03T15:23:18.023133', '2013-01-03T15:23:18.048133', '2013-01-03T15:24:47.298133', '2013-01-03T15:24:47.323133', '2013-01-03T15:26:31.873133', '2013-01-03T15:26:31.898133', '2013-01-03T15:26:31.923133', '2013-01-03T15:26:31.948133', '2013-01-03T15:26:31.973133', '2013-01-03T15:31:11.073133', '2013-01-03T15:31:29.698133', '2013-01-03T15:31:29.723133', '2013-01-03T15:31:29.748133', '2013-01-03T15:31:29.773133', '2013-01-03T15:37:07.423133', '2013-01-03T15:37:07.448133', '2013-01-03T15:37:07.473133', '2013-01-03T15:37:07.498133', '2013-01-03T15:37:07.523133', '2013-01-03T15:37:07.548133', '2013-01-03T15:37:07.573133', '2013-01-03T15:37:07.598133', '2013-01-03T15:37:18.973133', '2013-01-03T15:37:45.498133', '2013-01-03T15:37:58.373133', '2013-01-03T15:38:22.623133', '2013-01-03T15:38:37.473133', '2013-01-03T15:38:51.573133', '2013-01-03T15:38:51.598133', '2013-01-03T15:38:51.623133', '2013-01-03T15:38:51.648133', '2013-01-03T15:40:32.023133', '2013-01-03T15:40:32.048133', '2013-01-03T15:40:32.073133', '2013-01-03T15:40:32.098133', '2013-01-03T15:42:54.048133', '2013-01-03T15:44:49.098133', '2013-01-03T15:44:58.923133', '2013-01-03T15:45:32.723133', '2013-01-03T15:45:32.748133', '2013-01-03T15:45:32.773133', '2013-01-03T15:45:32.798133', '2013-01-03T15:45:32.823133', '2013-01-03T15:46:02.973133', '2013-01-03T15:46:02.998133', '2013-01-03T15:46:03.023133', '2013-01-03T15:46:03.048133', '2013-01-03T15:46:03.073133', '2013-01-03T15:46:03.098133', '2013-01-03T15:52:56.948133', '2013-01-03T15:54:04.098133', '2013-01-03T15:54:21.848133', '2013-01-03T15:54:31.323133', '2013-01-03T15:54:31.348133', '2013-01-03T15:54:52.448133', '2013-01-03T15:54:52.473133', '2013-01-03T15:54:52.498133', '2013-01-03T15:54:52.523133', '2013-01-03T15:54:52.548133', '2013-01-03T15:54:56.173133', '2013-01-03T15:54:56.198133', '2013-01-03T15:57:33.973133', '2013-01-03T15:57:33.998133'], 'start_time': '2013-01-03T15:00:00.023133', 'snclq': u'IU.RAO.10.BHZ', 'end_time': '2013-01-03T16:00:03.723133'}]

    **Plotting**

    .. code-block:: python

        #Plot identified spikes on top of waveform
        tr = st[0]
        d = []
        for i in spikes[0]['spike_times']:
            d.append(UTCDateTime(i)-tr.stats.starttime)
        plt.plot(tr.times(),tr.data)
        for i in d:
             plt.axvline(x=i,color='black')
        #plt.plot(d,tr.data[d],color='red',marker='o',markersize=4,linestyle='None')
        plt.xlabel('Seconds from %s' %str(tr.stats.starttime))
        plt.xlim([min(tr.times()),max(tr.times())])
        plt.ylabel('Amplitude')
        plt.title('%s WindowSize 41, threshold 6'%str(tr.id))
        plt.show()

    .. image:: _static/spikeMetricPlot.png

    """

    if logger == None:
        logger = Logger(None)

    # Initialize output list and spikeTime list
    out = []
    if len(st) > 1:
        pool = mp.Pool(processes=processes)
        args = []
        for i in range(len(st)):
            arg = [
                st[i],
                windowSize,
                threshold,
                selectivity,
                fixedThreshold,
                generateMasks,
                masksByTime,
                fortran,
            ]
            args.append(arg)
        out = pool.map(_pool_spikes, args)

    else:
        args = [
            st[0],
            windowSize,
            threshold,
            selectivity,
            fixedThreshold,
            generateMasks,
            masksByTime,
            fortran,
        ]
        d = _pool_spikes(args)
        out.append(d)

    if database is not None:
        database.insert_metric(out)

    return out


def _pool_spikes(args):
    tr = args[0]
    windowSize = args[1]
    threshold = args[2]
    selectivity = args[3]
    fixedThreshold = args[4]
    generateMasks = args[5]
    masksByTime = args[6]
    fortran = args[7]

    data = tr.data
    fs = tr.stats.sampling_rate
    starttime = tr.stats.starttime
    outliers = findOutliers(
        data,
        windowSize,
        threshold,
        selectivity,
        increment=1,
        fixedThreshold=fixedThreshold,
        fortran=fortran,
    )

    # There is at least one spike if there is at least one outlier.
    # Ignore adjacent outliers when determining the count of spikes.
    # But be sure there is at least one spike if there is at least one outlier
    spikeTime = []
    if len(outliers) != 0:
        countNonAdj = len(np.concatenate(np.where(np.diff(outliers) > 1))) + 1
        totalCount = len(outliers)
    else:
        totalCount = 0
        countNonAdj = 0

    # create mask
    masks = None
    if generateMasks and outliers:
        if masksByTime:
            masks = samples2time(np.asarray(outliers), fs, starttime)
        else:
            masks = np.zeros(len(data), dtype=int)
            masks[outliers] = 1

    # Calculate outlier time from starttime to put times in for spikes
    for o in outliers:
        time = tr.stats.starttime + o / tr.stats.sampling_rate
        spikeTime.append(time.isoformat())
    d = {
        "snclq": tr.get_id(),
        "spike_times": spikeTime,
        "total_spike_count": totalCount,
        "non_adjacent_spikes": countNonAdj,
        "start_time": tr.stats.starttime.isoformat(),
        "end_time": tr.stats.endtime.isoformat(),
        "mask": masks,
        "metric_name": "spikesMetric",
    }
    return d
