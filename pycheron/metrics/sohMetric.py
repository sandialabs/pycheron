#####################################################################################
# Copyright 2019 National Technology & Engineering Solutions of Sandia, LLC (NTESS).
# Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains
# certain rights in this software.
#####################################################################################
# NOTICE:
# For five (5) years from 10/21/2019 the United States Government is granted for
# itself and others acting on its behalf a paid-up, nonexclusive, irrevocable worldwide
# license in this data to reproduce, prepare derivative works, and perform publicly and
# display publicly, by or on behalf of the Government. There is provision for the
# possible extension of the term of this license. Subsequent to that period or any
# extension granted, the United States Government is granted for itself and others
# acting on its behalf a paid-up, nonexclusive, irrevocable worldwide license in this
# data to reproduce, prepare derivative works, distribute copies to the public,
# perform publicly and display publicly, and to permit others to do so. The specific
# term of the license can be identified by inquiry made to National Technology and
# Engineering Solutions of Sandia, LLC or DOE. NEITHER THE UNITED STATES GOVERNMENT,
# NOR THE UNITED STATES DEPARTMENT OF ENERGY, NOR NATIONAL TECHNOLOGY AND ENGINEERING
# SOLUTIONS OF SANDIA, LLC, NOR ANY OF THEIR EMPLOYEES, MAKES ANY WARRANTY, EXPRESS OR
# IMPLIED, OR ASSUMES ANY LEGAL RESPONSIBILITY FOR THE ACCURACY, COMPLETENESS, OR
# USEFULNESS OF ANY INFORMATION, APPARATUS, PRODUCT, OR PROCESS DISCLOSED, OR REPRESENTS
# THAT ITS USE WOULD NOT INFRINGE PRIVATELY OWNED RIGHTS. Any licensee of this software
# has the obligation and responsibility to abide by the applicable export control laws,
# regulations, and general prohibitions relating to the export of technical data.
# Failure to obtain an export control license or other authority from the Government
# may result in criminal liability under U.S. laws.
# (End of Notice)
####################################################################################

from future.builtins import *  # NOQA

__all__ = ["sohMetric"]

import obspy.io.mseed.util as util
import obspy
from pycheron.util.logger import Logger
import os
import warnings
import numpy as np
from pycheron.db.sqllite_db import Database


def sohMetric(
    st,
    data_quality=True,
    activity=True,
    io_clock=True,
    timing_quality=True,
    logger=None,
    database_config=None,
    generateMasks=False,
    masksByTime=True,
    noGPSTimeThreshold=0,
    poorTQThreshold=60,
    suspectTimeThreshold=1,
    ampSatThreshold=0,
    digFilterChgThreshold=2,
    clipThreshold=0,
    spikesThreshold=0,
    glitchThreshold=0,
    missingPadThreshold=0,
    tsyncThreshold=0,
    calibThreshold=0,
    timingCThreshold=0,
):
    # fmt: off
    """
    Extracts miniSEED quality flags and timing quality associated with the ObsPy stream object. This method will count
    all set flag bits (data quality, activity, and io/clock) in the fixed section of the
    data header in a Mini-SEED file and returns the total count for each flag type. By default, all flags are returned.
    To return just one set of bit flags (data quality/activity/io_clock), set the optional parameter to True and other
    options to False.

    :param st: ObsPy Stream object
    :type st: obspy.core.stream.Stream
    :param data_quality: Return data quality flags
    :type data_quality: bool
    :param activity: Return activity flags
    :type activity: bool
    :param io_clock: Return IO/Clack flags
    :type io_clock: bool
    :param timing_quality: Return timing quality information
    :type timing_quality: bool
    :param logger: logger object
    :type logger: pycheron.util.logger.Logger
    :param database_config: dictionary containing the necessary parameters to create
                            a pycheron Database object. 
                            These include "db_name", "session_name", "overwrite", "manual", "wfdb_conn"
    :type database_config: dict
    :param generateMasks: Return generated masks. Boolean mask types generated only, and generated for the whole data
                          that spans the issue, as flags don't indicate the exact record it was discovered.
    :type generateMasks: bool
    :param masksByTime: Boolean to determine whether masks are generated by time. If True, masks will be generated with
                        a start/end time, if false, they will be generated as boolean array.
    :type masksByTime: bool
    :param noGPSTimeThreshold: Clock unlocked threshold (from i/o clock bit 5). If value above theshold then values are
                               masked (default = 0)
    :type noGPSTimeThreshold: int
    :param poorTQThreshold: Threshold to determine if poor timing quality exists. If value below threshold then
                            values are masked (default = 60).
    :type poorTQThreshold: int
    :param suspectTimeThreshold: Threshold to determine if suspect time tag exists (from data quality bit 7). If value
                                 above threshold then values masked (default = 1)
    :type suspectTimeThreshold: int
    :param ampSatThreshold: Threshold to determine if amplitude saturation exists (from data quality bit 0). If value
                            above threshold then values masked (default = 0)
    :type ampSatThreshold: int
    :param digFilterChgThreshold: Threshold to determine if digital filter charging exists (from data quality bit 6).
                                  If value above threshold then values masked (default = 2)
    :type digFilterChgThreshold: int
    :param clipThreshold: Threshold to determine if clipping occurred (from data quality bit 1). If value above
                          threshold then values masked (default = 0)
    :type clipThreshold: int
    :param spikesThreshold: Threshold to determine if detected spikes exists (from data quality bit 2). If value above
                            threshold then values masked (default = 0)
    :type spikesThreshold: int
    :param glitchThreshold: Threshold to determine if detected glitch exists (from data quality bit 3). If value above
                            threshold then values masked (default = 0)
    :type glitchThreshold: int
    :param missingPadThreshold: Threshold to determine if missing/padded data exists (from data quality bit 4). If value
                                above threshold then values masked (default = 0)
    :type missingPadThreshold: int
    :param tsyncThreshold: Threshold to determine if telemetry sync errors exists (from data quality bit 5). If value
                           above threshold then values masked (default = 0)
    :type tsyncThreshold: int
    :param calibThreshold: Threshold to determine if calibration signals present (from activity bit 0). If value
                           above threshold then values masked (default = 0)
    :type calibThreshold: int
    :param timingCThreshold: Threshold to determine if timing correction exists (from activity bit 1). If value above
                             threshold then values masked (default = 0)
    :type timingCThreshold: int

    :return: list of dictionaries with the following keys and types

                * metric_name (`str`)
                * start_time (`str`)
                * end_time (`str`)
                * network (`str`)
                * station (`str`)
                * location (`str`)
                * data_quality_flag_counts (`dict`)
                * data_quality_flag_percentages (`dict`)
                * activity_flag_counts (`dict`)
                * activity_flag_percentages (`dict`)
                * io_clock_flag_counts (`dict`)
                * io_clock_flag_percentages (`dict`)
                * timing_quality (`dict`), includes timing statistics and timing correction information
                * record count (`int`)
                * num_records_used (`int`)
                * noTime (`bool`) boolean value indicating whether clock locked exceeded noGPSTimeThreshold
                * poorTQ (`bool`) boolean value indicating whether poor timing quality exists, if less than
                                  poorTQThreshold
                * suspectTime (`bool`) boolean value indicating whether suspect time exceeded suspectTimeThreshold
                * ampSat (`bool`) boolean value indicating whether amplitude saturation exceeded ampSatThreshold
                * digFilterChg (`bool`) boolean value indicating whether digiter Filter charging exceeded
                                        digFilterChgThreshold
                * clip (`bool`) boolean value indicating whether clip exceeded clipThreshold
                * spikes (`bool`) boolean value indicating whether spikes exceeded spikesThreshold
                * glitch (`bool`) boolean value indicating whether glitch exceeded glitchThreshold
                * missingPad (`bool`) boolean value indicating whether missingPad exceeded missingPadThreshold
                * tsyncErrors (`bool`) boolean value indicating whether telemetry sync errors exceeded tsyncThreshold
                * calib (`bool`) boolean value indicating whether calib exceeded calibThreshold
                * timingCor (`bool`) boolean value indicating whether timing correction counts exceeded timingCThreshold
                # Masks map to the same bool values above. dict is masksByTime, otherwise ndarray
                * noTimeMasks (`dict or numpy.ndarray`)
                * poorTQMasks (`dict or numpy.ndarray`)
                * suspectTimeMasks (`dict or numpy.ndarray`)
                * ampSatMasks (`dict or numpy.ndarray`)
                * digFilterChgMasks (`dict or numpy.ndarray`)
                * clipMasks (`dict or numpy.ndarray`)
                * spikesMasks (`dict or numpy.ndarray`)
                * glitchMasks (`dict or numpy.ndarray`)
                * missingPadMasks (`dict or numpy.ndarray`)
                * tsyncMasks (`dict or numpy.ndarray`)
                * calibMasks (`dict or numpy.ndarray`)
                * tcMasks (`dict or numpy.ndarray`)

    :rtype: list

    The miniSEED flags and timing_qual values are described in the SEED manual. [#]_

    "Each Stream object contains "accumulators" with counts of the number of times each bit flag was set during the
    parsing of a miniSEED file. Metrics are reported for a subset of these flags"
    (https://cran.r-project.org/web/packages/IRISMustangMetrics/IRISMustangMetrics.pdf)

    This method will count all set Data Quality, I/O Clock, and Activity flag bits in the fixed section of the data
    header in a Mini-SEED file and returns the total count and percentages for each flag type.

    Additionally it returns timing_correction, timing_count, and timing statistics information (e.g., min, max)
    Number of records used and record count are also included.

    * This metric does not follow the original code implmentation from IRISMustangMetrics but follows the conceptual
      idea of it to produce *some* of the same statistical products. Python has ObsPy which makes the calculation of
      SOH flags a simple command. Thereafter the data are aggregated to create some of the same output products to match
      the IRISMustangMetrics package. As we draw on original ideas from the package, we cite it here:
      IRISMustangMetrics R Cran Package
      (Callahan, J., R. Casey, M. Templeton, and G. Sharer (2020, March 20). CRAN-Package IRISMustangMetrics.
      The Comprehensive R Archive Network. Retrieved from
      https://cran.r-project.org/web/packages/IRISMustangMetrics/index.html) and augmented and adapted for use within
      Pycheron

    **Bit Descriptions**

    .. code-block:: console

        Data Quality
        [Bit 0]	Amplifier saturation detected (station dependent)
        [Bit 1]	Digitizer clipping detected
        [Bit 2]	Spikes detected
        [Bit 3]	Glitches detected
        [Bit 4]	Missing/padded data present
        [Bit 5]	Telemetry synchronization error
        [Bit 6]	A digital filter may be charging
        [Bit 7]	Time tag is questionable

        Activity
        [Bit 0] 	Calibration signals present
        [Bit 1] 	Time correction applied
        [Bit 2] 	Beginning of an event, station trigger
        [Bit 3] 	End of the event, station detriggers
        [Bit 4] 	A positive leap second happened during this record
        [Bit 5] 	A negative leap second happened during this record
        [Bit 6] 	Event in progress

        I/O and Clock
        [Bit 0] 	Station volume parity error possibly present
        [Bit 1] 	Long record read (possibly no problem)
        [Bit 2] 	Short record read (record padded)
        [Bit 3] 	Start of time series
        [Bit 4] 	End of time series
        [Bit 5] 	Clock locked



    **Example**

    .. code-block:: python

        # data with no flags set
        no_flags = 'test/test_data/7a_cabn_bhe.884965.tar.mseed'
        # data with flags set
        flags = 'test/test_data/qualityflags.mseed'

        sohMetric(no_flags) #this will raise an error because there are no data flags associated with it
        >>> "sohMetric: No SOH flags associated with 7A.CABN"
        sohMetric(flags) #can set optional parameters to True to return only certain flag groups
        >>> {'io_clock_flags': 
                {'start_time_series': 0, 'end_time_series': 0, 'long_record_read': 0, 'clock_locked': 0, 
                'short_record_read': 0, 'station_volume': 0}, 
                'data_quality_flags': 
                    {'digital_filter_charging': 3, 'spikes': 7, 'suspect_time_tag': 2, 
                     'missing_padded_data': 5, 'digitizer_clipping': 8, 'glitches': 6, 
                     'amplifier_saturation': 9, 'telemetry_sync_error': 4}, 
                'metric_name': 'sohMetric', 'activity_flags': 
                    {'event_begin': 0, 'negative_leap': 0, 'event_in_progress': 0, 'event_end': 0, 
                     'time_correction_applied': 0, 'calibration_signal': 0, 'positive_leap': 0}}

    .. rubric:: Footnotes

    .. [#] http://www.fdsn.org/seed_manual/SEEDManual_V2.4.pdf

    """
    # fmt: on
    warnings.filterwarnings("ignore")

    # Set up logger
    if logger is None:
        logger = Logger(None)

    # Initialize empty list to append dictionaries of flags to
    sohFlags = []

    # Initialize masks
    noTimeMasks = None
    poorTQMasks = None
    suspectTimeMasks = None
    ampSatMasks = None
    digFilterChgMasks = None
    clipMasks = None
    spikesMasks = None
    glitchMasks = None
    missingPadMasks = None
    tsyncMasks = None
    calibMasks = None
    tcMasks = None

    # Need to actually calculate this on per trace (really probably per station basis is best) basis. The traces for the
    # same station should presumably have the same quality flags, but if there are different SNCLs in the stream object
    # this will calculate flags for each one. It's safer this way and allows for versatility of the input
    # Loop through traces in a stream, create a temporary file, then write output to it, so that can grab SOH flags
    for tr in st:
        st_filename = os.path.dirname(__file__) + "/temp.mseed"
        tr.write(st_filename)

        # Get SOH flags
        try:
            flags = util.get_flags(st_filename)

            # Start basic dictionary to append to
            all = {
                "metric_name": "sohMetric",
                "network": tr.stats.network,
                "station": tr.stats.station,
                "channel": tr.stats.channel,
                "location": tr.stats.location,
                "start_time": tr.stats.starttime.isoformat(),
                "end_time": tr.stats.endtime.isoformat(),
            }

            # If data_quality flags True, loop through dictionary to get out the keys and values and update the all dict
            # Grab counts and percentages
            if data_quality:
                dq = {}
                dp = {}
                for k, v in list(flags["data_quality_flags_counts"].items()):
                    dq.update({str(k): v})
                for k, v in list(flags["data_quality_flags_percentages"].items()):
                    dp.update({str(k): v})
                all.update({"data_quality_flag_counts": dq, "data_quality_percentages": dp})

            # If activity flags True, loop through dictionary to get out the keys and values and update the all dict
            # Grab counts and percentages
            if activity:
                ac = {}
                ap = {}
                for k, v in list(flags["activity_flags_counts"].items()):
                    ac.update({str(k): v})
                for k, v in list(flags["activity_flags_percentages"].items()):
                    ap.update({str(k): v})
                all.update({"activity_flag_counts": ac, "activity_flag_percentages": ap})

            # If io_clock flags True, loop through dictionary to get out the keys and values and update the all dict
            # Grab counts and percentages
            if io_clock:
                io = {}
                ip = {}
                for k, v in list(flags["io_and_clock_flags_counts"].items()):
                    io.update({str(k): v})
                for k, v in list(flags["io_and_clock_flags_percentages"].items()):
                    ip.update({str(k): v})
                all.update({"io_clock_flag_counts": io, "io_clock_flags_percentages": ip})

            # If timing_quality True, loop through dictionary to get out the keys and values and update the all dict
            # Grab timing quality info and statistics
            if timing_quality:
                try:
                    tq_stats = {
                        k: flags["timing_quality"][k]
                        for k in set(list(flags["timing_quality"].keys())) - {"all_values"}
                    }
                    tq = {
                        "timing_correction": flags["timing_correction"],
                        "timing_correction_count": flags["timing_correction_count"],
                        "timing_quality_record_count": flags["timing_quality"]["all_values"],
                        "timing_quality_statistics": tq_stats,
                    }
                    all.update({"timing_quality": tq})

                # If timing_quality is empty dictionary then just set both timing quality record and statistics to
                # the empty dict timing quality
                except KeyError:
                    tq = {
                        "timing_correction": flags["timing_correction"],
                        "timing_correction_count": flags["timing_correction_count"],
                        "timing_quality_record_count": flags["timing_quality"],
                        "timing_quality_statistics": flags["timing_quality"],
                    }
                    all.update({"timing_quality": tq})

            # Grab record count and number of records used and update the all dict
            all.update(
                {
                    "record_count": flags["record_count"],
                    "num_records_used": flags["number_of_records_used"],
                }
            )

            # Threshold boolean checks
            # No time check
            if flags["io_and_clock_flags_counts"]["clock_locked"] > noGPSTimeThreshold:
                noTime = 1
            else:
                noTime = 0
            # Timing quality check
            try:
                if 0 <= flags["timing_quality"]["all_values"].any() < poorTQThreshold:
                    poorTQ = 1
                else:
                    poorTQ = 0
            except KeyError:
                # Set to 0
                poorTQ = 0
            # Suspect time tag applied check
            if flags["data_quality_flags_counts"]["suspect_time_tag"] > suspectTimeThreshold:
                suspectTime = 1
            else:
                suspectTime = 0
            # Amplitude saturation check
            if flags["data_quality_flags_counts"]["amplifier_saturation"] > ampSatThreshold:
                ampSat = 1
            else:
                ampSat = 0
            # Digital filter charging check
            if flags["data_quality_flags_counts"]["digital_filter_charging"] > digFilterChgThreshold:
                digFilterChg = 1
            else:
                digFilterChg = 0
            # Digitizer clipping check
            if flags["data_quality_flags_counts"]["digitizer_clipping"] > clipThreshold:
                clip = 1
            else:
                clip = 0
            # Spikes check
            if flags["data_quality_flags_counts"]["spikes"] > spikesThreshold:
                spikes = 1
            else:
                spikes = 0
            # Glitches check
            if flags["data_quality_flags_counts"]["glitches"] > glitchThreshold:
                glitch = 1
            else:
                glitch = 0
            # Missing padded data check
            if flags["data_quality_flags_counts"]["missing_padded_data"] > missingPadThreshold:
                missingPad = 1
            else:
                missingPad = 0
            # Telemetry sync error check
            if flags["data_quality_flags_counts"]["telemetry_sync_error"] > tsyncThreshold:
                tsyncErrors = 1
            else:
                tsyncErrors = 0
            # Calib check
            if flags["activity_flags_counts"]["calibration_signal"] > calibThreshold:
                calib = 1
            else:
                calib = 0
            # Timing correction check
            if flags["timing_correction_count"] > timingCThreshold:
                timingCor = 1
            else:
                timingCor = 0

            # Update all dictionary with boolean checks
            all.update(
                {
                    "noTime": noTime,
                    "poorTQ": poorTQ,
                    "suspectTime": suspectTime,
                    "ampSat": ampSat,
                    "digFilterChg": digFilterChg,
                    "clip": clip,
                    "spikes": spikes,
                    "glitch": glitch,
                    "missingPad": missingPad,
                    "tsyncErrors": tsyncErrors,
                    "calib": calib,
                    "timingCor": timingCor,
                }
            )

            # Run through threshold checks to determine if need to create masks for the trace. If above threshold, sets
            # a mask for entire day as can't pinpoint exactly where it is
            if generateMasks:
                # If by time, generate dictionary of start/end times
                if masksByTime:
                    # No time check
                    if flags["io_and_clock_flags_counts"]["clock_locked"] > noGPSTimeThreshold:
                        noTimeMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Timing quality check
                    try:
                        if 0 <= flags["timing_quality"]["all_values"].any() < poorTQThreshold:
                            poorTQMasks = {
                                "start_time": tr.stats.starttime,
                                "end_time": tr.stats.endtime,
                            }
                    except KeyError:
                        # Will just stay None in this case, as defined above
                        pass
                    # Suspect time tag applied check
                    if flags["data_quality_flags_counts"]["suspect_time_tag"] > suspectTimeThreshold:
                        suspectTimeMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Amplitude saturation check
                    if flags["data_quality_flags_counts"]["amplifier_saturation"] > ampSatThreshold:
                        ampSatMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Digital filter charging check
                    if flags["data_quality_flags_counts"]["digital_filter_charging"] > digFilterChgThreshold:
                        digFilterChgMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Digitizer clipping check
                    if flags["data_quality_flags_counts"]["digitizer_clipping"] > clipThreshold:
                        clipMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Spikes check
                    if flags["data_quality_flags_counts"]["spikes"] > spikesThreshold:
                        spikesMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Glitches check
                    if flags["data_quality_flags_counts"]["glitches"] > glitchThreshold:
                        glitchMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Missing padded data check
                    if flags["data_quality_flags_counts"]["missing_padded_data"] > missingPadThreshold:
                        missingPadMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Telemetry sync error check
                    if flags["data_quality_flags_counts"]["telemetry_sync_error"] > tsyncThreshold:
                        tsyncMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Calib check
                    if flags["activity_flags_counts"]["calibration_signal"] > calibThreshold:
                        calibMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }
                    # Timing correction check
                    if flags["timing_correction_count"] > timingCThreshold:
                        tcMasks = {
                            "start_time": tr.stats.starttime,
                            "end_time": tr.stats.endtime,
                        }

                # If masksByTime set to false, create a binary array
                else:
                    # No time check
                    if flags["io_and_clock_flags_counts"]["clock_locked"] > noGPSTimeThreshold:
                        noTimeMasks = np.ones(len(tr.data), dtype=int)
                    # Timing quality check
                    try:
                        if 0 <= flags["timing_quality"]["all_values"].any() < poorTQThreshold:
                            poorTQMasks = np.ones(len(tr.data), dtype=int)
                    except KeyError:
                        # Will just stay None in this case, as defined above
                        pass
                    # Suspect time tag applied check
                    if flags["data_quality_flags_counts"]["suspect_time_tag"] > suspectTimeThreshold:
                        suspectTimeMasks = np.ones(len(tr.data), dtype=int)
                    # Amplitude saturation check
                    if flags["data_quality_flags_counts"]["amplifier_saturation"] > ampSatThreshold:
                        ampSatMasks = np.ones(len(tr.data), dtype=int)
                    # Digital filter charging check
                    if flags["data_quality_flags_counts"]["digital_filter_charging"] > digFilterChgThreshold:
                        digFilterChgMasks = np.ones(len(tr.data), dtype=int)
                    # Digitizer clipping check
                    if flags["data_quality_flags_counts"]["digitizer_clipping"] > clipThreshold:
                        clipMasks = np.ones(len(tr.data), dtype=int)
                    # Spikes check
                    if flags["data_quality_flags_counts"]["spikes"] > spikesThreshold:
                        spikesMasks = np.ones(len(tr.data), dtype=int)
                    # Glitches check
                    if flags["data_quality_flags_counts"]["glitches"] > glitchThreshold:
                        glitchMasks = np.ones(len(tr.data), dtype=int)
                    # Missing padded data check
                    if flags["data_quality_flags_counts"]["missing_padded_data"] > missingPadThreshold:
                        missingPadMasks = np.ones(len(tr.data), dtype=int)
                    # Telemetry sync error check
                    if flags["data_quality_flags_counts"]["telemetry_sync_error"] > tsyncThreshold:
                        tsyncMasks = np.ones(len(tr.data), dtype=int)
                    # Calib check
                    if flags["activity_flags_counts"]["calibration_signal"] > calibThreshold:
                        calibMasks = np.ones(len(tr.data), dtype=int)
                    # Timing correction check
                    if flags["timing_correction_count"] > timingCThreshold:
                        tcMasks = np.ones(len(tr.data), dtype=int)

                # Add masks to all dictionary
                all.update(
                    {
                        "noTimeMasks": noTimeMasks,
                        "poorTQMasks": poorTQMasks,
                        "suspectTimeMasks": suspectTimeMasks,
                        "ampSatMasks": ampSatMasks,
                        "digFilterChgMasks": digFilterChgMasks,
                        "clipMasks": clipMasks,
                        "spikesMasks": spikesMasks,
                        "glitchMasks": glitchMasks,
                        "missingPadMasks": missingPadMasks,
                        "tsyncMasks": tsyncMasks,
                        "calibMasks": calibMasks,
                        "tcMasks": tcMasks,
                    }
                )

            # Add masks to all dictionary. Since generateMasks=False in this case they will all be None
            all.update(
                {
                    "noTimeMasks": noTimeMasks,
                    "poorTQMasks": poorTQMasks,
                    "suspectTimeMasks": suspectTimeMasks,
                    "ampSatMasks": ampSatMasks,
                    "digFilterChgMasks": digFilterChgMasks,
                    "clipMasks": clipMasks,
                    "spikesMasks": spikesMasks,
                    "glitchMasks": glitchMasks,
                    "missingPadMasks": missingPadMasks,
                    "tsyncMasks": tsyncMasks,
                    "calibMasks": calibMasks,
                    "tcMasks": tcMasks,
                }
            )

            # Loop
            os.remove(st_filename)

            # Append all before clearing it for the next trace
            sohFlags.append(all)

        # If SOH flags don't exist for sncl, let users know
        except (TypeError, ValueError, UnboundLocalError):
            st = obspy.read(st_filename)
            sncql = st[0].get_id().split(".")
            logger.error("sohMetric(): No SOH flags associated with " + sncql[0] + "." + sncql[1])
            # Remove file when complete
            os.remove(st_filename)

    # Insert data into database if available
    if database_config is not None:
        database = Database(**database_config)
        database.insert_metric(sohFlags)

    return sohFlags
